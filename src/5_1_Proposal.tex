
\chapter{Online VECM proposal}
Financial time series are known for their non-stationary behaviour. However,
sometimes they exhibit some stationary linear combinations. When this happens,
it is said that those time series are cointegrated. The Vector Error Correction
Model (VECM) is an econometric model which characterises the joint dynamic
behaviour of a set of cointegrated variables in terms of forces pulling towards
equilibrium. In this study, we propose an Online VEC model (OVECM) which
optimises how model parameters are obtained using a sliding window of the most
recent data. Our proposal also takes advantage of the long-run relationship
between the time series in order to obtain improved execution times. Our
proposed method is tested using four foreign exchange rates with a frequency of
1-minute, all related to the USD currency base. OVECM is compared with VECM and
ARIMA models in terms of forecasting accuracy and execution times. We show that
OVECM outperforms ARIMA forecasting and enables execution time to
be reduced considerably while maintaining good accuracy levels compared with
VECM.

\vspace{0.5cm} 

\section{The problem}
In finance, it is common to find variables with a long-run and/or a short-run
equilibrium relationship. This relationship is called cointegration and it
reflects the idea of that some set of variables cannot wander too far away from
each other. 

Cointegration means that one or more combinations of these variables is
stationary even though individually they are not.

Some financial models, such as  vector error correction model (VECM), take advantage of
this property and describe the joint behaviour of several cointegrated
financial instruments.

VECM is a special case of the vector autoregressive model (VAR). VAR is a linear
model which express future values in terms of its own history and other
variables past values. If cointegration exists, VECM allows to introduce an
error correction term due to its cointegration estimation error. 

VECM as well as VAR model parameters are obtained using ordinary least squares
method (OLS). Since OLS involves many calculations, the parameter estimation
method is computationally expensive when the number of past values and
observations considered increases. Moreover, OLS is an ill-posed problem which
admits an infinite number of solutions. 

Ridge regression method (RR) tackles this ill-posed problem and is usually
formulated instead of OLS. RR includes a regularisation parameter that leads to
better generalisation capability. However, RR is still computationally
expensive dealing with large datasets. Recently, online learning algorithms
have been proposed to solve problems with large data sets because of their
simplicity and their ability of updating the model when new data is available. 

We propose an online formulation of the VEC model based on the
AAR method considering only a sliding window of the most recent data. The
algorithm introduces matrix optimisations in order to reduce the number of
operations. Our method is later tested with financial data from the foreign
exchange market.


\section{Methodology} \label{sec:methodology}

Since VECM parameter estimation is computationally expensive, we propose an
online version of VECM (OVECM).  OVECM considers only a sliding window of the
most recent data. Moreover, since cointegration vectors represent long-run
relationships which vary little in time, OVECM determines firstly if they require calculation. 

OVECM also implements matrix optimisations in order to reduce execution time,
such as updating matrices with new data, removing old data and introducing new
cointegration vectors.

Algorithm~\ref{alg:proposal} shows our OVECM proposal which considers the
following:

\begin{itemize}
\item The function \texttt{getJohansen} returns cointegration vectors given by
the Johansen method considering the trace statistic test at 95\%
significance level.
\item The function \texttt{vecMatrix} returns the matrices~(\ref{eq:vecA})
and~(\ref{eq:vecY}) that allows VECM to be solved.
\item The function \texttt{vecMatrixOnline} returns the
matrices~(\ref{eq:vecA}) and~(\ref{eq:vecY}) aggregating new data and removing
the old one, avoiding calculation of the matrix $\mathbf{A}$ from scratch.
\item Out-of-sample outputs are saved in the variables 
$\mathbf{Y}_{\text{true}}$ and $\mathbf{Y}_{\text{pred}}$.
\item The model is solved using OLS.
\item In-sample outputs are saved in the variables $\Delta
\mathbf{y}_{\text{true}}$ and $\Delta \mathbf{y}_{\text{pred}}$.
\item The function \texttt{mape} gets the in-sample MAPE for the $l$ time
series.
\item Cointegration vectors are obtained at the beginning and when they are required to be updated. This updating is decided based on the in-sample MAPE of the last $n$ inputs. The average of all
MAPEs are stored in the variable $e$. If the average of MAPEs
($\texttt{mean}(e)$) is above a certain error given by the mean\_error threshold, cointegration vectors are updated.
\item If new cointegration vectors are required, the function
\texttt{vecMatrixUpdate} only updates the corresponding columns of matrix
$\mathbf{A}$ affected by those vectors (see equation~\ref{eq:vecA}).
\end{itemize}

\begin{algorithm}[ht]
\begin{algorithmic}[1]
\REQUIRE $\,$ \\
$\mathbf{y}$: matrix with $N$ input vectors and $l$ time series\\
$p$: number of past values \\
$L$: sliding window size ($L<N$) \\
$\text{mean\_error}$: MAPE threshold \\
$n$: interpolation points to obtain MAPE \\
\ENSURE  $\,$ \\
$\{\mathbf{y}_{\text{pred}}[L+1],\dots,\mathbf{y}_{\text{pred}}[N]\}$: model predictions 
\FOR { $i =0$ to $N-L$ }
    \STATE $\mathbf{y}_i \gets \mathbf{y}[i:i+L]$
	\IF {i = 0 }
	    \STATE{$v \gets \texttt{getJohansen}(\mathbf{y}_i,p)$}
	    \STATE{$[\mathbf{A} \quad \mathbf{Y}] \gets
        \texttt{vecMatrix}(\mathbf{y}_i,p,v)$}
	\ELSE
	    \STATE{$[\mathbf{A} \quad \mathbf{Y}] \gets
        \texttt{vecMatrixOnline}(\mathbf{y}_i,p,v,\mathbf{A},\mathbf{Y})$}
        \STATE $\Delta \mathbf{Y}_{\text{pred}}[i] \gets \mathbf{A}[-1,:] \times \mathbf{X}$
    \ENDIF
    \STATE $\mathbf{X} \gets \texttt{OLS} (\mathbf{A},\mathbf{Y})$
    \STATE $e \gets \texttt{mape}(\mathbf{Y}[-n,:],\mathbf{A}[-n,:] \times \mathbf{X})$
    \IF {$\texttt{mean}(e) > \text{mean\_error}$}
	    \STATE{$v \gets \texttt{getJohansen}(\mathbf{y}_i,p)$}
	    \STATE{$\mathbf{A} \gets
        \texttt{vecMatrixUpdate}(\mathbf{y}_i,p,v,\mathbf{A})$}
        \STATE $\mathbf{X} \gets \texttt{OLS} (\mathbf{A},\mathbf{Y})$
    \ENDIF
\ENDFOR
\STATE $\mathbf{Y}_{\text{true}} \gets \mathbf{Y}[L+1:N]$
\STATE $\mathbf{Y}_{\text{pred}}\gets 
\mathbf{Y}[L:N-1] +\Delta \mathbf{Y}_{\text{pred}}$
\end{algorithmic}
\caption{OVECM: Online VECM}
\label{alg:proposal}
\end{algorithm}

A pseudocode of the algorithm \ref{alg:proposal} is detailed in the appendix \ref{fig:pseudocodigo}.

Our proposal was compared against VECM and ARIMA. Both algorithms were adapted
to an online context in order to get a reasonable comparison with our proposal
(see algorithms \ref{alg:SLVECM} and \ref{alg:SLARIMA}). VECM and ARIMA are
called with a sliding window of the most recent data, whereby the models are
updated at every time step.

\begin{algorithm}[ht]
\begin{algorithmic}[1]
\REQUIRE $\,$ \\
$\mathbf{y}$: matrix with $N$ input vectors and $l$ time series\\
$p$: number of past values \\
$L$: sliding window size ($L<N$) \\
\ENSURE  $\,$ \\
$\{ \mathbf{y}_{\text{pred}}[L+1],\dots,\mathbf{y}_{\text{pred}}[N]\}$: model predictions 
\FOR { $i =0$ to $N-L$ }
    \STATE $\mathbf{y}_i \gets \mathbf{y}[i:i+L+1]$
        \STATE $model = VECM(\mathbf{y}_i, p)$
        \STATE $\mathbf{Y}_{\text{pred}}[i] = model.predict(\mathbf{y}[i+L])$
\ENDFOR
\STATE $\mathbf{Y}_{\text{true}} = \mathbf{y}[i+L+1:N] $
\end{algorithmic}
\caption{SLVECM: Sliding window VECM}
\label{alg:SLVECM}
\end{algorithm}

Since we know out time series are I(1) SLARIMA is called with $d=1$. ARIMA is
executed for every time series. 

\begin{algorithm}[ht]
\begin{algorithmic}[1]
\REQUIRE $\,$ \\
$\mathbf{y}$: matrix with $N$ input vectors and $l$ time series\\
$p$: autoregressive order \\
$d$: integrated order\\
$q$: moving average order\\
$L$: sliding window size ($L<N$) \\
\ENSURE  $\,$ \\
$\{ \mathbf{y}_{\text{pred}}[L+1],\dots,\mathbf{y}_{\text{pred}}[N]\}$: model predictions 
\FOR { $i =0$ to $N-L$ }
\FOR { $j =0$ to $l-1$ }
    \STATE $\mathbf{y}_i \gets \mathbf{y}[i:i+L+1,j]$
        \STATE $model = ARIMA(\mathbf{y}_i, (p,d,q))$
        \STATE $\mathbf{Y}_{\text{pred}}[i,j] = model.predict(\mathbf{y}[i+L,j])$
\ENDFOR
\ENDFOR
\STATE $\mathbf{Y}_{\text{true}} = \mathbf{y}[i+L+1:N,:] $
\end{algorithmic}
\caption{SLARIMA: Sliding window ARIMA}
\label{alg:SLARIMA}
\end{algorithm}

Both OVECM and SLVECM time complexity is dominated by Johansen method which is
$O(n^3)$. Thus, both algorithms order is $O(Cn^3)$ where $C$ is the number of
iterations. 

    
\section{Results} \label{sec:results}

\subsection{Data} \label{sec:unitroot}
Tests of SLVECM, SLARIMA and our proposal OVECM were carried out using foreign
four exchange data rates: EURUSD, GBPUSD, USDCHF and USDJPY. This data was
collected from the free database Dukascopy which gives access to the Swiss
Foreign Exchange Marketplace ~\cite{Dukascopy2014}.

The reciprocal of the last two rates (CHFUSD, JPYUSD) were used in order to
obtain the same base currency for all rates.  The tests were done using
1-minute frequency from ask prices which corresponded to 1.440 data points per
day from the 11th to the 15th of August 2014.

\subsection{Unit root tests} \label{sec:unitroot}
Before running the tests, we firstly checked if they were I(1) time series
using the Augmented Dickey Fuller (ADF) test.

\begin{table}[h!]
\caption{Unit roots tests}
\label{tab:adf}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
& \textbf{Statistic} & \textbf{Critical value} & \textbf{Result}\\
\hline
EURUSD          & -0.64 & -1.94 & True       \\
$\Delta$EURUSD & -70.45   & -1.94 & False       \\
GBPUSD          & -0.63   & -1.94 & True          \\
$\Delta$GBPUSD & -54.53   & -1.94 & False       \\
CHFUSD          & -0.88   & -1.94 & True         \\
$\Delta$CHFUSD & -98.98   & -1.94 & False       \\
JPYUSD          & -0.65 & -1.94 & True        \\
$\Delta$JPYUSD & -85.78 & -1.94 & False     \\ 
\hline
\end{tabular}
\end{center}
\end{table}


Table~\ref{tab:adf} shows that all currency rates cannot reject the unit root
test but they rejected it with their first differences. This means that all of
them are I(1) time series and we are allowed to use VECM and therefore OVECM.


\subsection{Parameter selection} \label{sec:paramselection}

In order to set OVECM parameters: windows size $L$ and lag order $p$,
we propose to use several window sizes: $L = 100, 400, 700, 1000$. For every window size $L$ we chose lag order with minimum AIC.

ARIMA parameters were also obtained using AIC.
Parameters optimisation is presented in table~\ref{tab:params}:

\begin{table}[ht]
\caption{Parameters optimisation. VECM order and ARIMA parameters were selected
using AIC.}
\label{tab:params}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Windows size $L$ & VECM & ARIMA\\
 $L$ & order $(p)$ & order $(p,d,q)$ \\
\hline
100 & 2 & p=2,d=1,q=1\\
400 & 5 & p=1,d=1,q=1\\
700 & 3 &p=2,d=1,q=1\\
1000 &3 & p=2,d=1,q=1\\
\hline
\end{tabular}
\end{center}
\end{table}

In OVECM we also define a mean\_error variable, which was defined based on the
in-sample MAPEs. Figure \ref{fig:mapes} shows how MAPE moves and how mean\_error
variable help us to decide whether new cointegration vectors are needed.

\begin{figure}[!h]
  \centering
   \includegraphics[width = 7.5cm]{img/mapes} 
  \caption{In-sample MAPEs example for 50 minutes. The average of them is
  considered to obtain new cointegration vectors.}
  \label{fig:mapes}
 \end{figure}



\subsection{Execution times} \label{sec:exectimes}
We ran OVECM and SLVECM 400 iterations. SLARIMA execution time is excluded
because its is not comparable with OVECM and SLVECM. SLARIMA was created based
on statsmodels library routine ARIMA.

The execution times are shown in the table~\ref{tab:extimes}.

\begin{table}[h!]
\caption{Execution times}
\label{tab:extimes}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
& $L$ & order & e  & Time[s] \\
\hline
OVECM & 100 &p=2  & 0      & 2.492\\
OVECM & 100 &p=2  & 0.0026  & 1.606\\
SLVECM & 100 &p=2& -- & 2.100\\
\hline
OVECM & 400 & p=5  & 0      & 3.513\\
OVECM & 400 &p=5  & 0.0041  & 2.569\\
SLVECM & 400 & p=5 & -- & 3.222\\
\hline
OVECM & 700 &p=3  & 0      & 3.296\\
OVECM & 700 &p=3  & 0.0032  & 2.856\\
SLVECM & 700 &p=3 & -- & 3.581\\
\hline
OVECM & 1000 & p=3 & 0      & 4.387\\
OVECM & 1000 & p=3  & 0.0022  & 2.408\\
SLVECM & 1000 & p=3  & -- & 3.609\\
\hline
\end{tabular}
\end{center}
\end{table}

It is clear that execution time depends directly on $L$ and $p$ since they
determine the size of matrix $\mathbf{A}$ and therefore affect the OLS function
execution time.
It is worthy of note that execution time also depends on mean\_error because it
determines how many times OVECM will recalculate cointegration vectors which is
an expensive routine.

Figure~\ref{fig:mapes} shows an example of the in-sample MAPE for 50 iterations.
When the average of the in-sample MAPEs is above mean\_error new cointegration
vectors are obtained. In consequence, OVECM performance increases when
mean\_error increases. However, this could affect accuracy, but
table~\ref{tab:stats} shows that using an appropriate mean\_error doesn't affect
accuracy considerable. 

\subsection{Performance accuracy} \label{sec:performacc}

Table~\ref{tab:stats} shows in-sample and out-of-sample performance measures:
MAPE, MAE and RMSE for OVECM, SLVECM and SLARIMA. Test were done using the
parameters defined in table \ref{tab:params}.  We can see that OVECM has very
similar performance than SLVECM and this support the theory that cointegration
vectors vary little in time. Moreover, OVECM also out performed SLARIMA based on
these three performance measures. 


\begin{table*}[ht!]
\caption{Model measures}
\label{tab:stats}
\begin{center}
\begin{tabular}{|l|l|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Model} & \multicolumn{3}{|c|}{In-sample} &
\multicolumn{3}{|c|}{Out-of-sample} \\ 
\hline
\hline
Method & $L$ & Parameters & e & 
MAPE & MAE& RMSE& 
MAPE & MAE& RMSE \\
\hline
 OVECM  &   100  &  P=2& 0.0026  &  0.00263&  0.00085&  0.00114&  0.00309&  0.00094&  0.00131\\
 OVECM  &   400  &  P=5& 0.0041  &  0.00378&  0.00095&  0.00127&  0.00419&  0.00103&  0.00143\\
 OVECM  &   700  &  P=3& 0.0032  &  0.00323&  0.00099&  0.00130&  0.00322&  0.00097&  0.00132\\
 OVECM  &   1000 &  P=3& 0.0022  &  
 \textbf{0.00175}&  \textbf{0.00062}&  \textbf{0.00087} &  
 \textbf{0.00172}&  \textbf{0.00061}&  \textbf{0.00090}\\
\hline
 SLVECM  &   100 &  P=2& -  &  0.00262&  0.00085&  0.00113&  0.00310&  0.00095&  0.00132\\
 SLVECM  &   400 &  P=5& -  &  0.00375&  0.00095&  0.00126&  0.00419&  0.00103&  0.00143\\
 SLVECM  &   700 &  P=3& -  &  0.00324&  0.00099&  0.00130&  0.00322&  0.00098&  0.00132\\
 SLVECM  &   1000 &  P=3& -  &  
 \textbf{0.00174}&  \textbf{0.00061}&  \textbf{0.00087}&  
 \textbf{0.00172}&  \textbf{0.00061}&  \textbf{0.00090}\\
\hline
SLARIMA & 100  &p=2, d=1, q=1 & - & 0.00285  &  0.00110  &  0.00308  &  0.00312  &0.00098  &  0.00144 \\
SLARIMA & 400  &p=1, d=1, q=1 & - & 0.00377  &  0.00101  &  0.00128  &  0.00418 & 0.00106 & 0.00145 \\
SLARIMA & 700  &p=2, d=1, q=1 & - & 0.00329  &  0.00102  &  0.00136  &  0.00324  & 0.00097  &  0.00133 \\
SLARIMA & 1000 &p=2, d=1, q=1 & - & \textbf{0.00281}  & \textbf{0.00074}  &  \textbf{0.00105}  &  \textbf{0.00177} & \textbf{0.00063}  &  \textbf{0.00092} \\
\hline
\end{tabular}
\end{center}
\end{table*}

We can also notice that in-sample performance in OVECM and SLVECM is related
with the out-of-sample performance.  This differs with SLARIMA which models with
good in-sample performance are not necessarily good out-of-sample models.
Moreover OVECM outperformed SLARIMA using the same window size.

Figure ~\ref{fig:accuracy} shows the out-of-sample forecasts made by our
proposal OVECM with the best parameters found based on table~\ref{tab:stats}
which follows the time series very well.  

\begin{figure}[h]
  \vspace{-0.2cm}
  \centering
   \includegraphics[width = 7.5cm]{img/accuracy} 
  \caption{OVECM forecasting accuracy example for 50 minutes using $L = 1000$ and $p =3$}
  \label{fig:accuracy}
 \end{figure}



\section{Conclusions} \label{sec:conclusions}

A new online vector error correction method was presented. 
We have shown that our proposed OVECM considerably reduces execution times
without compromising solution accuracy.  OVECM was compared with VECM and ARIMA
with the same sliding window sizes and OVECM outperformed both in terms of
execution time. Traditional VECM slightly outperformed our proposal but the
OVECM execution time is lower.
This reduction of execution time is mainly because OVECM avoids the cointegration vector
calculation using the Johansen method. The condition for getting new vectors is
given by the mean\_error variable which controls how many times the Johansen method is
called. Additionally, OVECM introduces matrix optimization in order to get the
new model in an iterative way.
We could see that our algorithm took much less than a minute at every
step. This means that it could also be used with higher frequency data and would
still provide responses before new data arrives.  

For future study, it would be interesting to improve the out-of-sample forecast
by considering more explicative variables, to increase window sizes or trying new
conditions to obtain new cointegration vectors. 

Since OVECM is an online algorithm which optimizes processing time, it could be
used by investors as an input for strategy robots. Moreover, some technical
analysis methods could be based on its output. 


