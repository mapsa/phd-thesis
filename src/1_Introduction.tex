\chapter{Introduction}\label{ch:introduction}

\vspace{0.5cm} 

"An individual economic variable, views as a time series, can wander extensively
and yet some pairs of series may be expected to move so that they do not drift
far apart."-Robert F. Engle and Clive W.J. Granger~\cite{engle1987}.\\
In this introduction we present the scope, objectives, hypothesis and
organization of this thesis.


\section{Scope of this research}

The stochastic behaviour of financial time series, its incrementing
amount of data available and the need of performing accurate forecasting in
short periods of time has motivated researchers to create efficient and fast
algorithms. This study involves interdisciplinary knowledge such as: finance,
scientific computing, high performance computing, machine learning, physics
among others.

Forecasting financial time series have been modeled using classical statistical
models. More recently , machine learning models have been extensively used in
forecasting. However, getting model parameters is a computational challenge.
The computational complexity of machine learning algorithms has become a
limiting factor for problems that require processing large volumes of data and
where the response time is crucial.

Therefore, algorithms that process large amount of data in a short period of
time are required.  Online learning algorithms have been developed to solve
large-scale problems since they process an instance at a time, updating the
model at each step incrementally. This is opposed to the batch algorithms where
a phase of training that uses a large collection of historical data is first
required and the resulting model is later used to predict.  

The specific scope of this study is to use financial time series features in
order to design a forecasting algorithm which ensures accuracy and low response
times. Cointegration is the main feature studied and it refers that one or more
linear combinations of these variables are stationary even though individually
they are not~\cite{engle87}.  Some models, such as the Vector Error Correction
(VECM), take advantage of this property and describe the joint behaviour of
several cointegrated variables.

In this thesis, we propose an online formulation of the VECM called Onlive VECM
(OVECM) based on consideration of only a sliding window of the most recent data.
The algorithm introduces matrix optimizations in order to reduce the number of
operations and also takes into account the fact that cointegration vector space
doesn't experience large changes with small changes in the input data. Moreover,
RR instead of OLS is used to solve VECM. Our method is later tested using four
currency rates from the foreign exchange market with different frequencies.  Model
efectiveness is focused on out-of-sample forecast rather than in-sample fitting.
This criteria allows the OVECM prediction capability to be expressed rather than
just explaining data history. Our method performance is compared with its
optimal offline algorithm.


\section{Research Objectives}
The main motivation for this research is the develpment of efficient methods for
forecasting financial time series.

The specific objectives of this research are,
\begin{itemize}
\item $\Large \mathcal{O}_1$: \emph{A review of the literature on time series
analysis models including machine learning techniques.}
\item $\Large \mathcal{O}_2$: \emph{Development of a set of know features of the
studied time series and applied them to improve forecasting.}
\item $\Large \mathcal{O}_3$: \emph{Development of parallel and efficient
algorithms to ensure quick time responses.}
\item $\Large \mathcal{O}_4$: \emph{Deep mathematical analysis of the proposal
and financial concepts involved.}
\item $\Large \mathcal{O}_5$: \emph{Design and implement representative set of
experiments in order to show when and why proposal performs better.}
\end{itemize}


\section{Research Hypothesis}


The main research hypothesis explored in this dissertation is the following \\

\textit{Hypothesis llll . }

\section{Organization of this Thesis}

Chapter 1 contains ...





%\section{Hypotheses}
%
%
%Volatility forecasting has been a largely studied and different approaches have arisen to describe its stochastic behaviour. It is well-known that volatility depends on many factors, but most of the existing models only consider a few of them. In order to introduce more factors easily, classic machine learning models have been studied and their performance have shown to be successfull in comparison with most used volatility models. However, their training process is computationally expensive and it is not possible to update the model with new market information before new information arrives. Online learning methods can also include more factors into a model, but they process one example at a time to update an existing model incrementally without having a training phase, thus they improve response times and are more suitable for financial applications.
%
%
%The thesis hypotheses are the following:
%
%\begin{enumerate} 
%\item Machine learning based models that consider more volatility explanatory factors will adapt and perform better than popular volatility forecasting models based only on returns or a few factors.
%\item Stylized facts can be efficiently introduced as explanatory factors and improve model performance.
%\item The use of online learning methods will allow inclusion of as many variables as needed to ensure low response times.  
%\end{enumerate}
%
%\section{General Objective}
%To design and implement an online learning model for volatility forecasting capable of adapting to their non-stationary behaviour using volatility factors as model input ensuring low response times.  
%\section{Specific Objectives}
%The specific objectives to be followed in this thesis are:
%\begin{enumerate}
%  \item To determine the best volatility factors based on their stylized facts and their performance in machine learning models.
%  \item To determine the best sampling of high frequency time series.
%  \item To define the best realized volatility proxy based on the literature and experimental results.
%  \item To design and implement a novel online learning algorithm with large input factors capable of ensuring low response time.
%  \item To modify the original algorithm using kernel trick and evaluate its performance.
%  \item To compare performance of the most popular algorithms for volatility forecasting such as ARFIMA, GARCH and SV models.
%  \item To assess the predictive capacity of the proposed model using the SPA test.
%  \item To compare the performance of the most popular models and the proposed model using real financial data.
%\end{enumerate}


%\section{Thesis proposal}
%
%This thesis proposal is to build an algorithm to forecast realized volatility in financial markets considering not only intraday returns but also other explanatory volatility variables. Because of the amount of high frequency data to be considered and short response times required in financial applications, the algorithm will be formulated in online mode. The online algorithm will also allow the shifting problem to be tackled while being adaptive to wild changes in the volatility process.
%The online learning model will be formulated considering the following:
%
%\begin{description}%[leftmargin=0.4cm]\itemsep4pt
%    \item[large volumes of data:] high frequency data will be used to estimate realized volatility. The frequency to be considered will be 10 to 15 minutes. This frequency will be analysed using signal processing theory. 
%    \item[non-stationary data:] volatility is a time series known because of its non-stationary feature, so statistics will be studied before using the model.
%    \item[stylized facts:] there are several well-documented features about financial time series volatility called stylized facts~\cite{poon+granger2003} that can be included in the model.
%    \item[low response time:] the model has to be simple but powerful in order to achieve the response time needed. If the model is extended to real time data, ticks can arrive at rates of milliseconds and the model should respond at the same rate or less.
%    \item[financial data:] the model can be constructed using data of stocks or different derivatives such as options and futures. The chosen implicit volatility model will depend on the data type.
%    \item[input vector:] currently, many models are only based on expected returns, but volatility is a complex variable which depends also on many factors studied in the literature such as trading volume, the tick rate, time of the day and the behaviour of the market as a hole~\cite{gatheral2006}. All these factors can improve the design of the proposed online algorithm.
%    \item[kernel version:] the online algorithm will be later kernelised in order to map the input data into a high dimensional feature space (kernel trick) which will provide better properties to design the solution.
%\end{description}
%
%The model proposed has to be compared with the current popular financial models of financial volatility such as: ARFIMA, GARCH, SV models and machine learning models. Performance will be measured using the realized volatility shown in equation~(\ref{eq:srv}) as a benchmark.
%
%In order to compare different models, apart from using the standard performance measurements like MAE and MSE, the superior predictive ability (SPA) methodology proposed by Hansen and Lunde~\cite{hansen+lunde2006} will also be studied. SPA is a test to compare two or more forecasting models at the same time giving a relative performance measurement of a base model in comparison with alternative models. 
%
%The model will be compared against traditional financial volatility models such as Black-Scholes, SV, GARCH and ARFIMA using different forecast errors measurements. Although the best way to measure forecast errors should be the investor returns, this implies knowing how the model information is used as a strategy, so this information is not going to be included in this thesis. Therefore, in order to compare the different volatility forecast models, popular evaluation measurements will be used. In the literature the following are commonly used: {\em Mean Error} (ME), {\em Mean Square Error} (MSE), {\em Mean Absolute Error} (MAE) and {\em Mean Absolute Percent Error} {MAPE} and others are less commonly used such as LINEX loss function which weight differently positive and negative errors. In ~\cite{granger1999} Granger describes a variety of non-symmetric loss function including LINEX. The superior predictive ability (SPA) methodology proposed by Hansen and Lunde~\cite{hansen+lunde2006} will also be studied 
%which allows comparison of two or more forecasting models at the same time giving a relative performance measurement of a base model compared with alternative models.  All these measurements will be out-of-sample in order to show their predictive power.
